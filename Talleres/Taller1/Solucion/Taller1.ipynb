{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwSVrlFfEdny"
      },
      "source": [
        "# Taller 1. Introduccion practica a Redes Neuronales. Introduccion a Keras y Tensor Flow\n",
        "\n",
        "Nombres: Manuel Sanchez y Allan Ramirez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivs4feaHEcQM"
      },
      "source": [
        "## Ejercicio I\n",
        "(10 pts) Explique muy brevemente y con sus propias palabras los siguientes conceptos (puede\n",
        "investigarlos pero al escribir trate de no tener ninguna fuente abierta).\n",
        "\n",
        "\n",
        "\n",
        "*   Inteligencia artificial\n",
        "*   Machine Learning (Aprendizaje de máquinas)\n",
        "*   Aprendizaje supervisado, no supervisado y reforzado\n",
        "*   Datos de entrenamiento, prueba y validación\n",
        "*   Método de validación cruzada\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ouo02zPEb91"
      },
      "source": [
        "## Ejercicio II\n",
        "(10 pts) Diseñe una red de perceptrones usando el modelo McCulloch-Pitts (cada neurona tiene una entrada y una salida binaria) que sea equivalente a las funciones logicas “or” y “and”\n",
        "para una entrada binaria.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuXpxvd8ETM8"
      },
      "source": [
        "# Ejercicio III\n",
        "\n",
        "(40 pts) Creación y entrenamiento de una red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEmMDN8V6kPJ",
        "outputId": "1ceccbc8-f244-4005-b7c3-bb8d932048b3"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhUeME93BXMl"
      },
      "source": [
        "Vamos a programar nuestra primer red neuronal. Utilizaremos dicha red para reconocer dıgitos. Usaremos el conjunto de datos MNIST, que cuenta con miles de imagenes de dıgitos escritos a mano de 28×28 pixeles en escala de grises. El conjunto cuenta con un conjunto\n",
        "de entrenamiento de 60 mil imagenes y un conjunto de prueba de 10 mil imagenes (tomadas de forma independiente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri3mIXIhBUQD",
        "outputId": "21fa9aa9-1ee5-44b7-a683-224778a2844c"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "(train_images , train_labels) , (test_images , test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzBJe4yvB6DX"
      },
      "source": [
        "Verificamos las dimensiones de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-kZZBo3CEqZ",
        "outputId": "8ce720bb-0f22-4d94-f1ca-5be644cf0f87"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "print(train_images.shape)\n",
        "print(train_labels)\n",
        "print(test_images.shape)\n",
        "print(test_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM7AODuhEG2B"
      },
      "source": [
        "Aca podemos ver que la que la base de datos son 60.000 matrices de 28x28 donde guarda el valor de los pixeles que usaremos para el entrenamiento de la red neuronal. Y el array que se visualiza es el número que le corresponde a la imagen. Asi mismo pasa con la imagenes de test con la diferencia que se utilizan 10.000 imagenes. Ahora veamos un poco como se distribuye cada uno de las imagenes a partir de un grafico de barras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "RebxLzfwDZhz",
        "outputId": "e30a51c1-36fd-40bf-b7e3-fb2caefba445"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "train_counts = np.bincount(train_labels)\n",
        "test_counts = np.bincount(test_labels)\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize=(8, 6))\n",
        "\n",
        "# Barplot para train_labels\n",
        "axs[0].bar(np.arange(len(train_counts)), train_counts, color='blue', alpha=0.7)\n",
        "axs[0].set_title('Barplot de train_labels')\n",
        "axs[0].set_xlabel('Etiquetas')\n",
        "axs[0].set_ylabel('Frecuencia')\n",
        "\n",
        "# Barplot para test_labels\n",
        "axs[1].bar(np.arange(len(test_counts)), test_counts, color='green', alpha=0.7)\n",
        "axs[1].set_title('Barplot de test_labels')\n",
        "axs[1].set_xlabel('Etiquetas')\n",
        "axs[1].set_ylabel('Frecuencia')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS8DmGdkDY1Q"
      },
      "source": [
        "Aquí se observa la cantidad de imágenes correspondientes a cada uno de los dígitos. En ambos casos, los datos se asemejan a una distribución uniforme, lo que indica que se intentó manejar la misma cantidad de imágenes para el ejercicio de reconocimiento de dígitos. Sin embargo, en ambas bases de datos, se destaca que hay más imágenes del dígito '1', mientras que el dígito con menos imágenes es el número '5'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OOuETxaD_Mx"
      },
      "source": [
        "Para que nuestra red reciba un vector y no una matriz, necesitamos cambiar la dimensionalidad de nuestros datos. Para eso podemos usar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDdANGjuImBD"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "train_images = train_images.reshape ((60000 , 28 * 28) )\n",
        "train_images = train_images.astype (\"float32\") / 255\n",
        "test_images = test_images.reshape ((10000 , 28 * 28) )\n",
        "test_images = test_images.astype (\"float32\") / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG4yGG5eJF3x"
      },
      "source": [
        "En esta celda, tanto para la base de datos de entrenamiento como para la de prueba, estamos ajustando la dimensionalidad de los datos para preparar adecuadamente los inputs para nuestra red neuronal. En lugar de trabajar con matrices de 28x28, transformamos los datos en un vector de longitud 784 (28x28) utilizando la función reshape(). Posteriormente, normalizamos estos vectores dividiendo cada valor por 255, lo que convierte la escala de los píxeles, originalmente entre 1 y 255, a un rango entre 0 y 1. Esto facilita el proceso de aprendizaje del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkP96_HVM1d7"
      },
      "source": [
        "Cree una red neuronal usando neuronas sigmoides y una capa final softmax. Para esto puede\n",
        "usar la funcion Sequential de keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvymRIvFM43r"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential ([\n",
        "layers.Dense(512 , activation =\"sigmoid\") ,\n",
        "layers.Dense (10 , activation =\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g44EQDwdNctW"
      },
      "source": [
        "En esta celda, la función Sequential se utiliza para crear un modelo secuencial, este modelo permite apilar capas de forma lineal, es decir, una capa tras otra.\n",
        "\n",
        "Para este caso se crea un modelo secuencial con dos capas densas (Dense):\n",
        "\n",
        "*   La primera capa tiene 512 neuronas con la función de activación sigmoide\n",
        "*   La segunda capa tiene 10 neuronas con la función de activación softmax\n",
        "\n",
        "La segunda capa de la red uso la función de activación softmax se utiliza principalmente cuando el objetivo es la clasificación multiclase. Esta función toma un vector de valores de entrada (que puede ser cualquier número real) y los convierte en probabilidades, es decir, en valores en el rango [0, 1] que suman 1.\n",
        "\n",
        "Cada neurona de la capa softmax produce un valor que representa la probabilidad de que la entrada pertenezca a una de las clases específicas. En este caso, se generará 10 probabilidades, una para cada digito posible. La clase con la probabilidad más alta es la predicción del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFa-A-leNdM5"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "model.compile( optimizer=\"SGD\",\n",
        "loss =\"SparseCategoricalCrossentropy\",\n",
        "metrics =[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERs5D7PNNzrS"
      },
      "source": [
        "La función compile se utiliza para configurar el modelo antes de entrenarlo. Es un paso crucial que define cómo el modelo se optimizará y evaluará durante el proceso de entrenamiento. Al llamar a model.compile(), se especifican tres aspectos clave: el optimizador, la función de pérdida y las métricas de evaluación. Aunque los tres parametros son claves para evaluar el modelo en el entrenamiento para este caso, es clave mencionar que la funcion de perdida usada como \"SparseCategoricalCrossentropy\", es adecuada para problemas de clasificación multiclase donde las etiquetas son enteros en lugar de vectores one-hot. Esta función de pérdida compara la probabilidad predicha para cada clase (producida por la activación softmax) con la clase real y calcula la pérdida para cada muestra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjh-JXVWN3Ul",
        "outputId": "f568ec89-0838-483b-a7e7-be16c1afc66e"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "model.fit( train_images, train_labels , epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrdt_0VsOQPl"
      },
      "source": [
        "La función fit es lo que utilizaremos para entrenar el modelo con los datos proporcionados. Es el método principal para ajustar los parámetros, donde el modelo iterativamente ajusta sus pesos para minimizar la función de pérdida definida durante la compilación. En los cuales nos pediran los datos de entrenamiento; los datos de prueba; la cantidad de epocas que se refiere a una pasada completa por todo el conjunto de datos de entrenamiento.\n",
        "\n",
        "Entonces lo que nos muestra los resultados del modelo, es que nos muestra cuanto tardo en ejecutarse una epoca y nos arroja al nivel de entrenamiento cuanto fue la precision y el valor de su funcion de perdida. Conforme van avanzando la epocas la precision debe aumentar y el valor de la funcion de perdida debe disminuir que es cierto, en este caso. Empezamos con una precision de 56.35% y funcion de perdida del 1.722 y al finalizar la 5 epocas quedaran en una precision del 89.19% y funcion de perdida del 0.3975 dandonos un indicio que el modelo esta teniendo un buen ajuste.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA77O4vaOI67",
        "outputId": "4bb3619f-e2f6-4d78-edfc-498db61f8c68"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '.venv (Python 3.12.5)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '\"i:/Mi unidad/Estudio/UniAndes/Semestre_3/Modelos avanzados 2/modelos_avanzados_deep_learning/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "test_loss , test_acc = model.evaluate( test_images , test_labels )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-pehS_rOFYr"
      },
      "source": [
        "La función evaluate se utiliza para medir el rendimiento de un modelo entrenado en un conjunto de datos de prueba. Esta función calcula la pérdida y las métricas que fueron definidas durante la compilación del modelo. En este caso, como parámetros se requieren los datos de las imágenes de prueba y sus respectivas etiquetas (labels) que identifican a qué tipo de imagen corresponde cada una. La función devuelve los mismos tipos de valores que se utilizaron durante el entrenamiento.\n",
        "\n",
        "En este ejemplo, se obtuvo una precisión de 0.8814, lo cual se puede considerar bueno para predecir dígitos en imágenes. La función de pérdida es de 0.4145, lo que es considerablemente bajo y cercano a los resultados obtenidos con los datos de entrenamiento. Esto sugiere que, además de estar bien ajustado, el modelo también arroja resultados bastante buenos para realizar predicciones en datos nuevos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikzoaa2YqBji"
      },
      "source": [
        "## Ejercicio 4\n",
        "\n",
        "(40 pts) Utilizando lo aprendido en el numeral anterior, diseñe por lo menos 4 redes diferentes (con distinto número de capas intermedias, distintos números de neuronas en ellas y distintas activaciones). Inicie y entrene sus redes múltiples veces. Describa las redes usadas y sus resultados. ¿Cuál es el mejor desempeño que logra conseguir (porcentaje de acierto con el conjunto de\n",
        "prueba)?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
